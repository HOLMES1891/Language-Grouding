# Language Grouding for Understanding Human Language
***
Nowadays Deep Learning models (such as Bert) have largely promoted the development of Natural Language Processing. The main idea is to learn language model from large corpus. Despite the great success on many different NLP tasks, such as QA, deep learning models still fail to really **understand** what human language is talking about. <br>
The sementic of human language is hidden beneath words we use to communicate with each other, which is closely related to the real world. Just as the introduction of Knowledge Graph from Google:
> > "things not strings".

Therefore, models only learn from corpus can never understand human language. We must let our deep learning models to learn lanaguage both from multi-dimensional data: video, audio, etc. Grounding symbols into real world objects is a prerequisite for understanding, which is a small step towards AGI.
<br>
Here is a reading list for Language Grounding and some related topics. Although these works have not draw much attention yet, I believe they are indispensable for AGI.
***
1. [**Language Grounding to Vision and Control**](https://katefvision.github.io/LanguageGrounding/)
2. [**Modularity of Mind**](https://plato.stanford.edu/entries/modularity-mind/#WhatMentModu) & [**Is the mind really modular?**](http://www.subcortex.com/PrinzModularity.pdf)
3. [**CraftAssist: A Framework for Dialogue-enabled Interactive Agents**](https://arxiv.org/abs/1907.08584)
4. [**A Computational Theory of Grounding in Natural Language Conversation**](https://apps.dtic.mil/dtic/tr/fulltext/u2/a289894.pdf)
5. [**BABYAI: FIRST STEPS TOWARDS GROUNDED LAN- GUAGE LEARNING WITH A HUMAN IN THE LOOP**](https://arxiv.org/pdf/1810.08272.pdf)

***
Some active researchers in this field:
* [Igor Labutov](https://igorlabutov.com) (LAER AI) 
* [Bishan Yang](http://www.cs.cmu.edu/~bishan/) (LAER AI)
* Yoshua Bengio (MILA)
* [David Traum](http://people.ict.usc.edu/~traum/)(USC)


